{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\"\n",
    "filename = data_folder + \"bfp-a3447q.pdf\"\n",
    "content_path= filename.split('.')[0]+'_v2_chunked.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, json\n",
    "json_read = pathlib.Path(content_path).read_text()\n",
    "data_content = json.loads(json_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 2: Sparse vector search with BM25\n",
    "\n",
    "We are going to use the same dataset as before. Let's download it and load into Qdrant, but this time we are going to create sparse vectors with BM25 only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We need to create a collection first. Qdrant will handle the IDF calculations, if we configure it to. That's required for BM25, otherwise it won't boost the rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name=\"bfp-a3447q_sparse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "# Create the collection with specified sparse vector parameters\n",
    "if not client.collection_exists(collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        sparse_vectors_config={\n",
    "            \"bm25\": models.SparseVectorParams(\n",
    "                modifier=models.Modifier.IDF,\n",
    "            )\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "FastEmbed comes with a BM25 implementation that we can use as any other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "title = 'RH-3CH-Sxx/RH-6CH-Sxx Special Specifications Manual' # can be obtained from doc metadata\n",
    "for index, chapter in enumerate(data_content):\n",
    "    # elements of data list:\n",
    "        # 0 - chapter level\n",
    "        # 1 - chapter name\n",
    "        # 2 - page number (1-based)\n",
    "        # 3 - chunk of text\n",
    "    if chapter[0] == 1:\n",
    "        root_chapter = chapter[1]\n",
    "    if 3*len(chapter[1]) > len(chapter[-1]): \n",
    "        print(f'{index}) Paragraphs not generated for chapter: {chapter[1]}')\n",
    "        continue    \n",
    "    # if index not in data_context.keys(): # if context not created, skip embedding\n",
    "    #     print(f'\\nChapter \"{chapter[1]}\" skipped', end='')\n",
    "    #     continue\n",
    "    context = \"\" # data_context[index]\n",
    "    text =  context + chapter[-1]\n",
    "    # print(f'\\n\\tChapter \"{chapter[1]}\" ', end='')\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector={\n",
    "            \"bm25\": models.Document(\n",
    "                text=text, \n",
    "                model=\"Qdrant/bm25\",\n",
    "            )\n",
    "        },\n",
    "        payload={\n",
    "            \"content\": chapter[-1],\n",
    "            \"main_chapter\": root_chapter,\n",
    "            \"chapter\": chapter[1],\n",
    "            \"manual\": title,\n",
    "            \"page\": chapter[2]\n",
    "        } #save all needed metadata fields\n",
    "    )\n",
    "    # print(\"encoded... \", end='')\n",
    "    points.append(point)\n",
    "    id += 1\n",
    "print(f\"Collection points gathered\")\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "print(f\"Collection {collection_name} upserted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\",\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results = search(\"rcready\", limit = 5)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Step 3: Qdrant search for combined vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'all-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    model_name, \n",
    "    trust_remote_code=True,\n",
    "    cache_folder=\"./models\"   # explicitly setting cache location\n",
    ")\n",
    "emb_dimensions = model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name=\"bfp-a3447q_hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the collection with both vector types\n",
    "if not client.collection_exists(collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\n",
    "            model_name: models.VectorParams(\n",
    "                size=emb_dimensions,  # Dimensionality of the vectors\n",
    "                distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "            ),\n",
    "        },\n",
    "        sparse_vectors_config={\n",
    "            \"bm25\": models.SparseVectorParams(\n",
    "                modifier=models.Modifier.IDF,\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    print(f\"New collection {collection_name} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We have to upload all the vectors into the newly created collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "title = 'RH-3CH-Sxx/RH-6CH-Sxx Special Specifications Manual' # can be obtained from doc metadata\n",
    "for index, chapter in enumerate(data_content):\n",
    "    # elements of data list:\n",
    "        # 0 - chapter level\n",
    "        # 1 - chapter name\n",
    "        # 2 - page number (1-based)\n",
    "        # 3 - chunk of text\n",
    "    \n",
    "    if chapter[0] == 1:\n",
    "        root_chapter = chapter[1]\n",
    "    if 3*len(chapter[1]) > len(chapter[-1]): \n",
    "        print(f'{index}) Paragraphs not generated for chapter: {chapter[1]}')\n",
    "        continue    \n",
    "\n",
    "    context = \"\" # data_context[index]\n",
    "    text =  context + chapter[-1]\n",
    "    \n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector={\n",
    "            model_name: model.encode(text).tolist(),\n",
    "            \"bm25\": models.Document(\n",
    "                text=text, \n",
    "                model=\"Qdrant/bm25\",\n",
    "            ),\n",
    "        },\n",
    "        payload={\n",
    "            \"content\": chapter[-1],\n",
    "            \"main_chapter\": root_chapter,\n",
    "            \"chapter\": chapter[1],\n",
    "            \"manual\": title,\n",
    "            \"page\": chapter[2]\n",
    "        } #save all needed metadata fields\n",
    "    )\n",
    "    points.append(point)\n",
    "    id += 1\n",
    "    \n",
    "print(f\"Collection points gathered\")\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "print(f\"Collection {collection_name} upserted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Step 4: Qdrant Universal Query API - prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=model.encode(query).tolist(),\n",
    "                using=model_name,\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\", \n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=\"How much of space is required to place controller?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# results = multi_stage_search(q, 5)\n",
    "print(*results, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=model.encode(query).tolist(),\n",
    "                using=model_name,\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"which signal confirms that servo is working?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results = rrf_search(q, limit= 5)\n",
    "print(len(results), \"results:\")\n",
    "print(*[payload for payload in results], sep=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
