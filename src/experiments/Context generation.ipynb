{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "827c2c1a-c860-4f09-9c30-affa61ce74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from jinja2 import Template\n",
    "import os\n",
    "import toml\n",
    "from google.genai import types\n",
    "from google import genai \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d36c5fa-1e8d-4084-8137-41fdc36052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptLoader:\n",
    "    def __init__(self, path: str = \"prompts.yaml\"):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.prompts = yaml.safe_load(f)\n",
    "\n",
    "    def render(self, name: str, **kwargs) -> str:\n",
    "        \"\"\"Render a named prompt with given variables.\"\"\"\n",
    "        template = Template(self.prompts[name])\n",
    "        return template.render(**kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d346e0a2-0ada-4399-98e3-dc3434b9356e",
   "metadata": {},
   "source": [
    "loader = PromptLoader(\"data/prompts.yaml\")\n",
    "prompt = loader.render(\n",
    "    \"context_extension\",\n",
    "    chunk=\">>This is the main chunk text.<<\",\n",
    "    neighbors=\">>This is the neighboring context text.<<\"\n",
    ")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4cbaa65-71d6-4f4f-8d95-4049f5ddf0f2",
   "metadata": {},
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    "    contents=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05a2a23c-4ecb-42f5-ab76-4fe095608b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/bfp-a3447q_chunked.txt\"\n",
    "output_path = \"data/bfp-a3447q_context.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d528f26-727e-4cb6-a821-160007678dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, json\n",
    "json_read = pathlib.Path(input_path).read_text()\n",
    "data = json.loads(json_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54f99f36-1727-4ae0-935b-0e766635d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_dict = dict()\n",
    "context_dict = dict()\n",
    "loader = PromptLoader(\"data/prompts.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f22985-fc22-4bb8-93bf-6aba53909d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"../../.streamlit/secrets.toml\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = config[\"gemini\"][\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45caa5b-a86c-42ca-9f91-95650f5056e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client()\n",
    "print(\"Client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "717e8448-16a0-405f-81fa-c19e17020624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Paragraphs not generated for chapter: 1 General configuration\n",
      "20) Paragraphs not generated for chapter: 1.6 Contents of the structural equipment\n",
      "25) Paragraphs not generated for chapter: 2 Robot arm\n",
      "26) Paragraphs not generated for chapter: 2.1 Standard specifications\n",
      "27) Paragraphs not generated for chapter: 2.1.1 Basic specifications\n",
      "48) Paragraphs not generated for chapter: 2.2.7 Protection specifications\n",
      "51) Paragraphs not generated for chapter: 2.4 Outside dimensions / Operating range diagram\n",
      "52) Paragraphs not generated for chapter: 2.4.1 Outside dimensions / Operating range diagram\n",
      "56) Paragraphs not generated for chapter: 2.4.2 Outside dimensions of machine cables\n",
      "59) Paragraphs not generated for chapter: 2.5 Tooling\n",
      "61) Paragraphs not generated for chapter: 2.5.2 Internal wiring and piping\n",
      "72) Paragraphs not generated for chapter: 3 Controller\n",
      "73) Paragraphs not generated for chapter: 3.1 Standard specifications\n",
      "77) Paragraphs not generated for chapter: 3.2 Names of each part\n",
      "79) Paragraphs not generated for chapter: 3.3 Outside dimensions/Installation dimensions\n",
      "82) Paragraphs not generated for chapter: 3.4 External input/output\n",
      "126) Paragraphs not generated for chapter: 4 Software\n",
      "127) Paragraphs not generated for chapter: 4.1 Functions and specifications of RH-3CH-Sxx/RH-6CH-Sxx\n",
      "138) Paragraphs not generated for chapter: 5 Instruction Manual\n",
      "140) Paragraphs not generated for chapter: 6 Safety\n",
      "154) Paragraphs generated in range [151:157] for chapter: 6.1.7 Examples of safety measures\n",
      "\tContext generated with end: ing the importance of stable power supply voltage.\n",
      "155) Paragraphs generated in range [152:158] for chapter: (1) External emergency stop connection [supplementary explanation]\n",
      "\tContext generated with end: s due to potential static noise and surge voltage.\n",
      "156) Paragraphs generated in range [153:159] for chapter: 6.2 Working environment\n",
      "\tContext generated with end: ty fences and classification of faults for wiring.\n",
      "157) Paragraphs generated in range [154:160] for chapter: (1) Power supply\n",
      "\tContext generated with end: d vibration (transportation and operation limits).\n",
      "158) Paragraphs generated in range [155:161] for chapter: (2) Noise\n",
      "\tContext generated with end: dust/oil mist are also highlighted as detrimental.\n",
      "159) Paragraphs generated in range [156:162] for chapter: (3) Temperature and humidity\n",
      "\tContext generated with end: an cause the robot arm surface to become very hot.\n",
      "160) Paragraphs generated in range [157:163] for chapter: (4) Vibration\n",
      "\tContext generated with end: d avoiding fumigants containing halogen materials.\n",
      "161) Paragraphs generated in range [158:164] for chapter: (5) Installation environment\n",
      "\tContext generated with end: ning fumigants that can cause product malfunction.\n",
      "162) Paragraphs generated in range [159:165] for chapter: 6.3 Precautions for handling\n",
      "\tContext generated with end: ectromagnetic compatibility in automation systems.\n",
      "163) Paragraphs generated in range [160:166] for chapter: 6.3 Precautions for handling\n",
      "\tContext generated with end:  coated surfaces is discouraged to prevent damage.\n",
      "164) Paragraphs not generated for chapter: 6.4 EMC installation guideline\n",
      "165) Paragraphs generated in range [162:168] for chapter: 6.4.1 Outlines\n",
      "\tContext generated with end: ypes, layout, control panel structure, and wiring.\n",
      "166) Paragraphs generated in range [163:169] for chapter: 6.4.2 EMC\n",
      "\tContext generated with end: subsection lists component parts for EMC measures.\n",
      "167) Paragraphs generated in range [164:170] for chapter: 6.4.3 EMC measures\n",
      "\tContext generated with end: outside dimensions and adaptation cable diameters.\n",
      "168) Paragraphs generated in range [165:171] for chapter: 6.4.4 Concrete example for RH-3CH/6CH series\n",
      "\tContext generated with end: lly the FR-BLF type from Mitsubishi Electric Corp.\n",
      "169) Paragraphs not generated for chapter: 6.4.5 Component parts for EMC measures\n",
      "170) Paragraphs generated in range [167:173] for chapter: (1) Ferrite core\n",
      "\tContext generated with end: signals such as mode changeover and error outputs.\n",
      "171) Paragraphs generated in range [168:173] for chapter: (2) Line noise filter\n",
      "\tContext generated with end: ffice address for MITSUBISHI ELECTRIC CORPORATION.\n",
      "172) Paragraphs not generated for chapter: 7 Appendix\n",
      "173) Paragraphs generated in range [172:173] for chapter: Appendix 1 ï¼š Classification of functions using external input/output signals\n",
      "\tContext generated with end: h a corporate head office address in Tokyo, Japan.\n"
     ]
    }
   ],
   "source": [
    "root_chapter_ix = 0\n",
    "window_size = 3 # max number of chunks to be taken before and ahead of selected chunk\n",
    "for index, chunk in enumerate(data):\n",
    "    if index in context_dict.keys():\n",
    "        continue\n",
    "    if chunk[0] == 1:\n",
    "        root_chapter_ix = index\n",
    "    if 2*len(chunk[1]) > len(chunk[-1]): # if chapter is empty, skip its context creation\n",
    "        print(f'{index}) Paragraphs not generated for chapter: {chunk[1]}')\n",
    "        continue\n",
    "    paragraph_start = max(root_chapter_ix, index - window_size)\n",
    "    paragraph_end = min(index + window_size + 1, len(data))\n",
    "    paragraph_list = [ d[-1] for d in data[paragraph_start:paragraph_end]]\n",
    "    paragraphs = '\\n'.join(paragraph_list)\n",
    "    print(f'{index}) Paragraphs generated in range [{paragraph_start}:{paragraph_end-1}] for chapter: {chunk[1]}')\n",
    "    paragraph_dict[index] = paragraphs\n",
    "    prompt = loader.render(\n",
    "        \"context_extension\",\n",
    "        chunk=chunk[-1],\n",
    "        neighbors=paragraphs\n",
    "    )\n",
    "    print(\"\\rPrompting standby...\",end='')\n",
    "    time.sleep(2)\n",
    "    print(\"\\rWaiting for generation...\",end='')\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "        ),\n",
    "        contents=prompt\n",
    "    )\n",
    "    print(f'\\r\\tContext generated with end: {response.text[-50:]}')\n",
    "    context_dict[index] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aadb888d-e743-40e2-a519-5e877f5fc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file=json.dumps(context_dict, indent=2)\n",
    "# Exporting data to output file for storage\n",
    "with open(output_path, mode='w+') as f_out:\n",
    "    f_out.write(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91167939-211d-4553-bb5a-0054cd9840b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
