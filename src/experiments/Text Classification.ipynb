{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm_validate = init_chat_model(\"gemini-2.0-flash-lite\", model_provider=\"google_genai\")\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "responsive_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are my personal representative. Recruiters might ask you about my skillset and project portfolio and other related things.\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    relativity: str = Field(\n",
    "        description=\"Validate whether user input is related to my skillset, project portfolio or me.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "classification_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are my personal representative. Recruiters might ask you about my skillset and project portfolio and other related things.\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class ClassificationTag(BaseModel):\n",
    "\n",
    "    category: str = Field(\n",
    "        description= \"Decide for which category user input is related the most.\",\n",
    "        strict=True,\n",
    "        examples=[\"about Me\", \"gallup\", \"experience\", \"programming\",\"projects\",\"projects\",\"development\",\"other\" ]\n",
    "    )\n",
    "class Classification(BaseModel):\n",
    "\n",
    "    aboutMe: str = Field(\n",
    "        description= \"Validate whether user input is related to me.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    gallup: str = Field(\n",
    "        description= \"Validate whether user input is related to my gallup strenghts\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    experience: str = Field(\n",
    "        description= \"Validate whether user input is related to my experience.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    programming: str = Field(\n",
    "        description= \"Validate whether user input is related to my programming skills.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    projects: str = Field(\n",
    "        description= \"Validate whether user input is related to my project portfolio.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "    development: str = Field(\n",
    "        description= \"Validate whether user input is related to my personal development.\",\n",
    "        enum=[\"True\", \"False\"]\n",
    "    )\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm_validate.with_structured_output(ClassificationTag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "inp = \"How did you implement change data capture in your portfolio work?\"\n",
    "# inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = classification_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../docs/faq.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    lines = text.split(\"\\n\")\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in lines:\n",
    "    prompt = classification_prompt.invoke({\"input\": inp})\n",
    "    response = structured_llm.invoke(prompt)\n",
    "    print(inp[:-1])\n",
    "    print(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"True\" in response.model_dump().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
